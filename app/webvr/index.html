<!DOCTYPE html>

<html lang="en">
<head>
<title>Web VR Polyfill - basic example</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, shrink-to-fit=no">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

<style>
html, body {
  width: 100%;
  height: 100%;
  background-color: #000;
  color: #fff;
  margin: 0px;
  padding: 0;
  overflow: hidden;
}

canvas {
  position: absolute;
  top: 0;
}

#buttons {
  position: fixed;
  top: 0;
  right: 0;
  z-index: 1;
  background: white;
}
</style>
</head>

<body>

  <div id="buttons">
    <button id="fullscreen">Fullscreen</button>
    <button id="vr">VR (WebVR/Mobile only)</button>
    <button id="reset">Reset</button>
  </div>

  <script>
  WebVRConfig = {
    BUFFER_SCALE: 1.0,
  };

  document.addEventListener('touchmove', function(e) {
    e.preventDefault();
  });
  </script>


  <script src="../scripts/controller.js"></script>






  <!-- three.js library -->
  <script src="js/three.js"></script>

  <!-- VRControls.js applies the WebVR transformations to a three.js camera object. -->
  <script src="js/VRControls.js"></script>

  <!-- VREffect.js handles stereo camera setup and rendering.  -->
  <script src="js/VREffect.js"></script>

  <script src="js/STLLoader.js"></script>


  <!-- A polyfill for the WebVR API.  -->
  <script src="js/webvr-polyfill.js"></script>

  <script src="../node_modules/three/examples/js/utils/GeometryUtils.js"></script>
  <script src="../scripts/components/fluid/FBOUtils.js"></script>


  <!-- Common vars -->
  <script src="../scripts/native.js"></script>



  <script type="x-shader/x-vertex" id="fboVert">
varying vec2 vUv;

void main()
{

vUv = vec2(uv.x, uv.y);

gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

}
  </script>
  <script type="x-shader/x-fragment" id="fboFrag">
// simulation
varying vec2 vUv;

uniform sampler2D tPositions;
uniform sampler2D origin;

uniform float timer;
uniform vec3 velocity;

vec4 mod289(vec4 x) {
return x - floor(x * (1.0 / 289.0)) * 289.0; }

float mod289(float x) {
return x - floor(x * (1.0 / 289.0)) * 289.0; }

vec4 permute(vec4 x) {
return mod289(((x*34.0)+1.0)*x);
}

float permute(float x) {
return mod289(((x*34.0)+1.0)*x);
}

vec4 taylorInvSqrt(vec4 r)
{
return 1.79284291400159 - 0.85373472095314 * r;
}

float taylorInvSqrt(float r)
{
return 1.79284291400159 - 0.85373472095314 * r;
}

vec4 grad4(float j, vec4 ip)
{
const vec4 ones = vec4(1.0, 1.0, 1.0, -1.0);
vec4 p,s;

p.xyz = floor( fract (vec3(j) * ip.xyz) * 7.0) * ip.z - 1.0;
p.w = 1.5 - dot(abs(p.xyz), ones.xyz);
s = vec4(lessThan(p, vec4(0.0)));
p.xyz = p.xyz + (s.xyz*2.0 - 1.0) * s.www;

return p;
}

// (sqrt(5) - 1)/4 = F4, used once below
#define F4 0.309016994374947451

float snoise(vec4 v)
{
const vec4  C = vec4( 0.138196601125011,  // (5 - sqrt(5))/20  G4
              0.276393202250021,  // 2 * G4
              0.414589803375032,  // 3 * G4
             -0.447213595499958); // -1 + 4 * G4

// First corner
vec4 i  = floor(v + dot(v, vec4(F4)) );
vec4 x0 = v -   i + dot(i, C.xxxx);

// Other corners

// Rank sorting originally contributed by Bill Licea-Kane, AMD (formerly ATI)
vec4 i0;
vec3 isX = step( x0.yzw, x0.xxx );
vec3 isYZ = step( x0.zww, x0.yyz );
//  i0.x = dot( isX, vec3( 1.0 ) );
i0.x = isX.x + isX.y + isX.z;
i0.yzw = 1.0 - isX;
//  i0.y += dot( isYZ.xy, vec2( 1.0 ) );
i0.y += isYZ.x + isYZ.y;
i0.zw += 1.0 - isYZ.xy;
i0.z += isYZ.z;
i0.w += 1.0 - isYZ.z;

// i0 now contains the unique values 0,1,2,3 in each channel
vec4 i3 = clamp( i0, 0.0, 1.0 );
vec4 i2 = clamp( i0-1.0, 0.0, 1.0 );
vec4 i1 = clamp( i0-2.0, 0.0, 1.0 );

//  x0 = x0 - 0.0 + 0.0 * C.xxxx
//  x1 = x0 - i1  + 1.0 * C.xxxx
//  x2 = x0 - i2  + 2.0 * C.xxxx
//  x3 = x0 - i3  + 3.0 * C.xxxx
//  x4 = x0 - 1.0 + 4.0 * C.xxxx
vec4 x1 = x0 - i1 + C.xxxx;
vec4 x2 = x0 - i2 + C.yyyy;
vec4 x3 = x0 - i3 + C.zzzz;
vec4 x4 = x0 + C.wwww;

// Permutations
i = mod289(i);
float j0 = permute( permute( permute( permute(i.w) + i.z) + i.y) + i.x);
vec4 j1 = permute( permute( permute( permute (
   i.w + vec4(i1.w, i2.w, i3.w, 1.0 ))
 + i.z + vec4(i1.z, i2.z, i3.z, 1.0 ))
 + i.y + vec4(i1.y, i2.y, i3.y, 1.0 ))
 + i.x + vec4(i1.x, i2.x, i3.x, 1.0 ));

// Gradients: 7x7x6 points over a cube, mapped onto a 4-cross polytope
// 7*7*6 = 294, which is close to the ring size 17*17 = 289.
vec4 ip = vec4(1.0/294.0, 1.0/49.0, 1.0/7.0, 0.0) ;

vec4 p0 = grad4(j0,   ip);
vec4 p1 = grad4(j1.x, ip);
vec4 p2 = grad4(j1.y, ip);
vec4 p3 = grad4(j1.z, ip);
vec4 p4 = grad4(j1.w, ip);

// Normalise gradients
vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));
p0 *= norm.x;
p1 *= norm.y;
p2 *= norm.z;
p3 *= norm.w;
p4 *= taylorInvSqrt(dot(p4,p4));

// Mix contributions from the five corners
vec3 m0 = max(0.6 - vec3(dot(x0,x0), dot(x1,x1), dot(x2,x2)), 0.0);
vec2 m1 = max(0.6 - vec2(dot(x3,x3), dot(x4,x4)            ), 0.0);
m0 = m0 * m0;
m1 = m1 * m1;
return 49.0 * ( dot(m0*m0, vec3( dot( p0, x0 ), dot( p1, x1 ), dot( p2, x2 )))
     + dot(m1*m1, vec2( dot( p3, x3 ), dot( p4, x4 ) ) ) ) ;

}

void main()
{
vec3 pos = texture2D( tPositions, vUv ).xyz;

pos.x += snoise(vec4(pos.x, pos.y, pos.z, timer/10000.0)) * 0.01;
pos.y += snoise(vec4(pos.x, pos.y, pos.z, 1.352+timer/10000.0)) * 0.01;
pos.z += snoise(vec4(pos.x, pos.y, pos.z, 12.352+timer/10000.0)) * 0.01;



// Write new position out
gl_FragColor = vec4(pos, 1.0);

}
  </script>

  <script type="x-shader/x-vertex" id="fboRenderVert">
uniform sampler2D map;

uniform float width;
uniform float height;

uniform float pointSize;

varying vec2 vUv;
varying vec4 vPosition;


// Pseudo random number generator
float rand(vec2 co)
{
return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
}


void main()
{

vUv = position.xy + vec2( 0.5 / width, 0.5 / height );

vec3 position = ( texture2D( map, vUv ).rgb  );

gl_PointSize = 0.9;
gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );

}
  </script>
  <script type="x-shader/x-fragment" id="fboRenderFrag">
uniform sampler2D map;
uniform float effector;

varying vec2 vUv;
varying vec4 vPosition;

void main()
{
gl_FragColor = vec4( 0.2,0.1,0.8,1.0 );
gl_FragColor *= 1.5;


}

</script>




  <script>
  // Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
  // Only enable it if you actually need to.

  var camera, scene;
  var geometry, material, mesh, mesh2, material2;
  var texSize = 512;
  var dispSize = {x:window.innerWidth, y:window.innerHeight};
  var data;
  var texture;
  var simulationShader;
  var rtTexturePos, rtTexturePos2;
  var fboParticles;
  var renderer = new THREE.WebGLRenderer({ alpha: true });
  var timer=0;

  var native = native;
  var renderer = new THREE.WebGLRenderer({antialias: false});
  renderer.setPixelRatio(Math.floor(window.devicePixelRatio));

  // Append the canvas element created by the renderer to document body element.
  document.body.appendChild(renderer.domElement);

  // Create a three.js scene.
  var scene = new THREE.Scene();

  // Create a three.js camera.
  var camera = new THREE.PerspectiveCamera(20, window.innerWidth / window.innerHeight, 1, 10000);

  // Apply VR headset positional data to camera.
  var controls = new THREE.VRControls(camera);

  // Apply VR stereo rendering to renderer.
  var effect = new THREE.VREffect(renderer);
  effect.setSize(window.innerWidth, window.innerHeight);


  // Add a repeating grid as a skybox.
  var boxWidth = 90;
  var loader = new THREE.TextureLoader();
  loader.load('../assets/box.png', onTextureLoaded);

  // Get the VRDisplay and save it for later.
  var vrDisplay = null;
  navigator.getVRDisplays().then(function(displays) {
    if (displays.length > 0) {
      vrDisplay = displays[0];

      // Kick off the render loop.
      vrDisplay.requestAnimationFrame(animate);
    }
  });

  function onTextureLoaded(texture) {
    texture.wrapS = THREE.RepeatWrapping;
    texture.wrapT = THREE.RepeatWrapping;
    texture.repeat.set(boxWidth, boxWidth);

    var geometry = new THREE.BoxGeometry(boxWidth, boxWidth, boxWidth);
    var material = new THREE.MeshBasicMaterial({
        map: texture,
        transparent: true,
        opacity: 1,
        color: 0x0B5394,
        side: THREE.BackSide
    });

    var skybox = new THREE.Mesh(geometry, material);
    scene.add(skybox);
  }

  // object
  var loader = new THREE.STLLoader();

  loader.load( '../assets/model.stl', function ( geometry ) {
      var material=new THREE.MeshNormalMaterial({
          linewidth: 0.01,
          wireframe: true,
          transparent: true,
          opacity: 1,
      });

      var mesh=new THREE.Mesh(geometry, material);
      mesh.name="model"
      mesh.scale.set(0.3, 0.3, 0.3);
      mesh.translateY(0)
      mesh.translateX(0)
      mesh.translateZ(0)
      mesh.rotateX(0)
      mesh.rotateZ(0)

      mesh.material.needsUpdate = true;
      scene.add(mesh);
  });

  // Request animation frame loop function
  var lastRender = 0;

  camera.needsUpdate = true;

  scene.position.z = -120;

  var object = scene.getObjectByName('model');







  // INIT FBO
  var data = new Float32Array( texSize * texSize * 3 );
  for (var i=0; i<data.length; i+=3){
      data[i] = Math.random() * 2-1;
      data[i+1] = Math.random() * 2-1;
      data[i+2] = 0.0;
  }
  texture = new THREE.DataTexture( data, texSize, texSize, THREE.RGBFormat, THREE.FloatType );
  texture.minFilter = THREE.NearestFilter;
  texture.magFilter = THREE.NearestFilter;
  texture.needsUpdate = true;

  rtTexturePos = new THREE.WebGLRenderTarget(texSize, texSize, {
      wrapS:THREE.RepeatWrapping,
      wrapT:THREE.RepeatWrapping,
      minFilter: THREE.NearestFilter,
      magFilter: THREE.NearestFilter,
      format: THREE.RGBFormat,
      type:THREE.FloatType,
      stencilBuffer: false
  });

  rtTexturePos2 = rtTexturePos.clone();

  simulationShader = new THREE.ShaderMaterial({

      uniforms: {
          tPositions: { type: "t", value: texture },
          origin: { type: "t", value: texture },
          timer: { type: "f", value: 0}
      },

      vertexShader: document.getElementById('fboVert').innerHTML,
      fragmentShader:  document.getElementById('fboFrag').innerHTML

  });

  fboParticles = new THREE.FBOUtils( texSize, renderer, simulationShader );
  fboParticles.renderToTexture(rtTexturePos, rtTexturePos2);

  fboParticles.in = rtTexturePos;
  fboParticles.out = rtTexturePos2;

  geometry2 = new THREE.Geometry();

  for ( var i = 0, l = texSize * texSize; i < l; i ++ ) {

      var vertex = new THREE.Vector3();
      vertex.x = ( i % texSize ) / texSize ;
      vertex.y = Math.floor( i / texSize ) / texSize;
      geometry2.vertices.push( vertex );
  }

  material2 = new THREE.ShaderMaterial( {

      uniforms: {

          "map": { type: "t", value: rtTexturePos },
          "width": { type: "f", value: texSize },
          "height": { type: "f", value: texSize },
          "pointSize": { type: "f", value: 1 },
          "effector" : { type: "f", value: 0 }

      },
      vertexShader: document.getElementById('fboRenderVert').innerHTML,
      fragmentShader: document.getElementById('fboRenderFrag').innerHTML,
      depthTest: true,
      transparent: true,
      blending: THREE.AdditiveBlending
  } );

  mesh2 = new THREE.Points( geometry2, material2 );
  scene.add( mesh2 );








///////REnder here
  function animate(timestamp) {
    var delta = Math.min(timestamp - lastRender, 500);
    lastRender = timestamp;

    simulationShader.uniforms.timer.value = timestamp;
    simulationShader.uniforms.timer.value = timestamp;

    // swap
    var tmp = fboParticles.in;
    fboParticles.in = fboParticles.out;
    fboParticles.out = tmp;

    simulationShader.uniforms.tPositions.value = fboParticles.in;
    fboParticles.simulate(fboParticles.out);
    material2.uniforms.map.value = fboParticles.out;

    // renderer.render( scene, camera );


    // Update VR headset position and apply to camera.
    controls.update();

    // Render the scene.
    effect.render(scene, camera);

    // Keep looping.
    vrDisplay.requestAnimationFrame(animate);

  }




  function onResize() {
    console.log('Resizing to %s x %s.', window.innerWidth, window.innerHeight);
    effect.setSize(window.innerWidth, window.innerHeight);
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
  }

  function onVRDisplayPresentChange() {
    console.log('onVRDisplayPresentChange');
    onResize();
  }

  // Resize the WebGL canvas when we resize and also when we change modes.
  window.addEventListener('resize', onResize);
  window.addEventListener('vrdisplaypresentchange', onVRDisplayPresentChange);

  // Button click handlers.
  document.querySelector('button#fullscreen').addEventListener('click', function() {
    enterFullscreen(renderer.domElement);
  });
  document.querySelector('button#vr').addEventListener('click', function() {
    vrDisplay.requestPresent([{source: renderer.domElement}]);
  });
  document.querySelector('button#reset').addEventListener('click', function() {
    vrDisplay.resetPose();
  });

  function enterFullscreen (el) {
    if (el.requestFullscreen) {
      el.requestFullscreen();
    } else if (el.mozRequestFullScreen) {
      el.mozRequestFullScreen();
    } else if (el.webkitRequestFullscreen) {
      el.webkitRequestFullscreen();
    } else if (el.msRequestFullscreen) {
      el.msRequestFullscreen();
    }
  }

  </script>

</body>

</html>
